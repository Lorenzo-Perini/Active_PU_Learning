{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Setup of the paper\n",
    "## 'Class Prior Estimation in Active Positive and Unlabeled Learning', IJCAI 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from scipy.io import arff\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random, math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from multiprocessing import Pool, freeze_support, cpu_count\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import collections\n",
    "from anomatools.models import SSDO\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from TIcE import *\n",
    "from Kernel_MPE_grad_threshold import *\n",
    "from evaluate_CAPe import *\n",
    "from CAPe import *\n",
    "\n",
    "def ignore_warnings():\n",
    "    import warnings\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "ignore_warnings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In order to reproduce the experiments in the paper, for each of the benchmark dataset, run the following code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WBC_norm_v02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(331)\n",
    "data = arff.loadarff('../files/csvfiles/Datasets/WBC_norm_v02.arff') #set your directory to upload the dataset\n",
    "df = pd.DataFrame(data[0])\n",
    "df['outlier'] = [string.decode(\"utf-8\") for string in df['outlier'].values]\n",
    "y = np.array([1 if string == 'yes' else 0 for string in df['outlier'].values], dtype = int)\n",
    "real_cont = sum(y)/len(y)\n",
    "class_prior = 1-real_cont\n",
    "data = df[df.columns[:9]].values             #entire data set\n",
    "\n",
    "tmp_cont = 0.1                               #first bet of 1-class prior\n",
    "k = 5                                        #number of new labels at each iteration (ntimes)\n",
    "ntimes = int(min(150, 0.5*len(data)) // k)   #number of querying iterations\n",
    "case = 2                                     #case 0 = perfect oracle, case 2 = imperfect oracle\n",
    "name_ds = 'WBC'                              #if you want to give a name to the final result...\n",
    "n_splits = 5                                 #splits in crossvalidation (stratified)\n",
    "n_iter = 5                                   #number of runs of the whole method\n",
    "\n",
    "#This function runs the experiments. Pay attention that it saves 2 files: F1 results and prior results.\n",
    "df1 = get_f1scores_wdiff_priors(data, y, real_cont, tmp_cont, k, ntimes, name_ds, case, n_splits, n_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuttle_withoutdupl_norm_v02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(331)\n",
    "data = arff.loadarff('../files/csvfiles/Datasets/Shuttle_withoutdupl_norm_v02.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "df['outlier'] = [string.decode(\"utf-8\") for string in df['outlier'].values]\n",
    "y = np.array([1 if string == 'yes' else 0 for string in df['outlier'].values], dtype = int)\n",
    "real_cont = sum(y)/len(y)\n",
    "class_prior = 1-real_cont\n",
    "data = df[df.columns[:9]].values             #entire data set\n",
    "\n",
    "skf2 = StratifiedKFold(n_splits=2, random_state=331, shuffle=True) #used to reduce the size...\n",
    "for _ , index in skf2.split(data, y):\n",
    "    data = data[index]\n",
    "    y = y[index]\n",
    "    break;\n",
    "    \n",
    "tmp_cont = 0.1                               #first bet of 1-class prior\n",
    "k = 5                                        #number of new labels at each iteration (ntimes)\n",
    "ntimes = int(min(150, 0.5*len(data)) // k)   #number of querying iterations\n",
    "case = 2                                     #case 0 = perfect oracle, case 2 = imperfect oracle\n",
    "name_ds = 'Shuttle'                          #if you want to give a name to the final result...\n",
    "n_splits = 5                                 #splits in crossvalidation (stratified)\n",
    "n_iter = 5                                   #number of runs of the whole method\n",
    "\n",
    "#This function runs the experiments. Pay attention that it saves 2 files: F1 results and prior results.\n",
    "df1 = get_f1scores_wdiff_priors(data, y, real_cont, tmp_cont, k, ntimes, name_ds, case, n_splits, n_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annthyroid_withoutdupl_norm_07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(331)\n",
    "data = arff.loadarff('../files/csvfiles/Datasets/Annthyroid_withoutdupl_norm_07.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "df['outlier'] = [string.decode(\"utf-8\") for string in df['outlier'].values]\n",
    "y = np.array([1 if string == 'yes' else 0 for string in df['outlier'].values], dtype = int)\n",
    "real_cont = sum(y)/len(y)\n",
    "class_prior = 1-real_cont\n",
    "data = df[df.columns[:21]].values             #entire data set\n",
    "\n",
    "skf2 = StratifiedKFold(n_splits=10, random_state=331, shuffle=True) #used to reduce the size...\n",
    "for _ , index in skf2.split(data, y):\n",
    "    data = data[index]\n",
    "    y = y[index]\n",
    "    break;\n",
    "    \n",
    "tmp_cont = 0.1                               #first bet of 1-class prior\n",
    "k = 5                                        #number of new labels at each iteration (ntimes)\n",
    "ntimes = int(min(150, 0.5*len(data)) // k)   #number of querying iterations\n",
    "case = 2                                     #case 0 = perfect oracle, case 2 = imperfect oracle\n",
    "name_ds = 'Annthyroid'                       #if you want to give a name to the final result...\n",
    "n_splits = 5                                 #splits in crossvalidation (stratified)\n",
    "n_iter = 5                                   #number of runs of the whole method\n",
    "\n",
    "#This function runs the experiments. Pay attention that it saves 2 files: F1 results and prior results.\n",
    "df1 = get_f1scores_wdiff_priors(data, y, real_cont, tmp_cont, k, ntimes, name_ds, case, n_splits, n_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WDBC_withoutdupl_norm_v02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(331)\n",
    "data = arff.loadarff('../files/csvfiles/Datasets/WDBC_withoutdupl_norm_v02.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "df['outlier'] = [string.decode(\"utf-8\") for string in df['outlier'].values]\n",
    "y = np.array([1 if string == 'yes' else 0 for string in df['outlier'].values], dtype = int)\n",
    "real_cont = sum(y)/len(y)\n",
    "class_prior = 1-real_cont\n",
    "data = df[df.columns[:30]].values            #entire data set\n",
    "\n",
    "tmp_cont = 0.1                               #first bet of 1-class prior\n",
    "k = 5                                        #number of new labels at each iteration (ntimes)\n",
    "ntimes = int(min(150, 0.5*len(data)) // k)   #number of querying iterations\n",
    "case = 2                                     #case 0 = perfect oracle, case 2 = imperfect oracle\n",
    "name_ds = 'WDBC'                             #if you want to give a name to the final result...\n",
    "n_splits = 5                                 #splits in crossvalidation (stratified)\n",
    "n_iter = 5                                   #number of runs of the whole method\n",
    "\n",
    "#This function runs the experiments. Pay attention that it saves 2 files: F1 results and prior results.\n",
    "df1 = get_f1scores_wdiff_priors(data, y, real_cont, tmp_cont, k, ntimes, name_ds, case, n_splits, n_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stamps_withoutdupl_norm_09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(331)\n",
    "data = arff.loadarff('../files/csvfiles/Datasets/Stamps_withoutdupl_norm_09.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "df['outlier'] = [string.decode(\"utf-8\") for string in df['outlier'].values]\n",
    "y = np.array([1 if string == 'yes' else 0 for string in df['outlier'].values], dtype = int)\n",
    "real_cont = sum(y)/len(y)\n",
    "class_prior = 1-real_cont\n",
    "data = df[df.columns[:9]].values             #entire data set\n",
    "\n",
    "tmp_cont = 0.1                               #first bet of 1-class prior\n",
    "k = 5                                        #number of new labels at each iteration (ntimes)\n",
    "ntimes = int(min(150, 0.5*len(data)) // k)   #number of querying iterations\n",
    "case = 2                                     #case 0 = perfect oracle, case 2 = imperfect oracle\n",
    "name_ds = 'Stamps'                           #if you want to give a name to the final result...\n",
    "n_splits = 5                                 #splits in crossvalidation (stratified)\n",
    "n_iter = 5                                   #number of runs of the whole method\n",
    "\n",
    "#This function runs the experiments. Pay attention that it saves 2 files: F1 results and prior results.\n",
    "df1 = get_f1scores_wdiff_priors(data, y, real_cont, tmp_cont, k, ntimes, name_ds, case, n_splits, n_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cardiotocography_withoutdupl_norm_05_v02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(331)\n",
    "data = arff.loadarff('../files/csvfiles/Datasets/Cardiotocography_withoutdupl_norm_05_v02.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "df['outlier'] = [string.decode(\"utf-8\") for string in df['outlier'].values]\n",
    "y = np.array([1 if string == 'yes' else 0 for string in df['outlier'].values], dtype = int)\n",
    "real_cont = sum(y)/len(y)\n",
    "class_prior = 1-real_cont\n",
    "data = df[df.columns[:21]].values             #entire data set\n",
    "\n",
    "skf2 = StratifiedKFold(n_splits=4, random_state=331, shuffle=True) #used to reduce the size...\n",
    "for _ , index in skf2.split(data, y):\n",
    "    data = data[index]\n",
    "    y = y[index]\n",
    "    break;\n",
    "    \n",
    "tmp_cont = 0.1                               #first bet of 1-class prior\n",
    "k = 5                                        #number of new labels at each iteration (ntimes)\n",
    "ntimes = int(min(150, 0.5*len(data)) // k)   #number of querying iterations\n",
    "case = 2                                     #case 0 = perfect oracle, case 2 = imperfect oracle\n",
    "name_ds = 'Cardiotocography'                 #if you want to give a name to the final result...\n",
    "n_splits = 5                                 #splits in crossvalidation (stratified)\n",
    "n_iter = 5                                   #number of runs of the whole method\n",
    "\n",
    "#This function runs the experiments. Pay attention that it saves 2 files: F1 results and prior results.\n",
    "df1 = get_f1scores_wdiff_priors(data, y, real_cont, tmp_cont, k, ntimes, name_ds, case, n_splits, n_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ionosphere_withoutdupl_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(331)\n",
    "data = arff.loadarff('../files/csvfiles/Datasets/Ionosphere_withoutdupl_norm.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "df['outlier'] = [string.decode(\"utf-8\") for string in df['outlier'].values]\n",
    "y = np.array([1 if string == 'yes' else 0 for string in df['outlier'].values], dtype = int)\n",
    "real_cont = sum(y)/len(y)\n",
    "class_prior = 1-real_cont\n",
    "data = df[df.columns[:32]].values            #entire data set\n",
    "\n",
    "tmp_cont = 0.1                               #first bet of 1-class prior\n",
    "k = 5                                        #number of new labels at each iteration (ntimes)\n",
    "ntimes = int(min(150, 0.5*len(data)) // k)   #number of querying iterations\n",
    "case = 2                                     #case 0 = perfect oracle, case 2 = imperfect oracle\n",
    "name_ds = 'Ionosphere'                       #if you want to give a name to the final result...\n",
    "n_splits = 5                                 #splits in crossvalidation (stratified)\n",
    "n_iter = 5                                   #number of runs of the whole method\n",
    "\n",
    "#This function runs the experiments. Pay attention that it saves 2 files: F1 results and prior results.\n",
    "df1 = get_f1scores_wdiff_priors(data, y, real_cont, tmp_cont, k, ntimes, name_ds, case, n_splits, n_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pima_withoutdupl_norm_20_v02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(331)\n",
    "data = arff.loadarff('../files/csvfiles/Datasets/Pima_withoutdupl_norm_20_v02.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "df['outlier'] = [string.decode(\"utf-8\") for string in df['outlier'].values]\n",
    "y = np.array([1 if string == 'yes' else 0 for string in df['outlier'].values], dtype = int)\n",
    "real_cont = sum(y)/len(y)\n",
    "class_prior = 1-real_cont\n",
    "data = df[df.columns[:8]].values             #entire data set\n",
    "\n",
    "tmp_cont = 0.1                               #first bet of 1-class prior\n",
    "k = 5                                        #number of new labels at each iteration (ntimes)\n",
    "ntimes = int(min(150, 0.5*len(data)) // k)   #number of querying iterations\n",
    "case = 2                                     #case 0 = perfect oracle, case 2 = imperfect oracle\n",
    "name_ds = 'Pima'                             #if you want to give a name to the final result...\n",
    "n_splits = 5                                 #splits in crossvalidation (stratified)\n",
    "n_iter = 5                                   #number of runs of the whole method\n",
    "\n",
    "#This function runs the experiments. Pay attention that it saves 2 files: F1 results and prior results.\n",
    "df1 = get_f1scores_wdiff_priors(data, y, real_cont, tmp_cont, k, ntimes, name_ds, case, n_splits, n_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PageBlocks_norm_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(331)\n",
    "data = arff.loadarff('../files/csvfiles/Datasets/PageBlocks_norm_10.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "df['outlier'] = [string.decode(\"utf-8\") for string in df['outlier'].values]\n",
    "y = np.array([1 if string == 'yes' else 0 for string in df['outlier'].values], dtype = int)\n",
    "real_cont = sum(y)/len(y)\n",
    "class_prior = 1-real_cont\n",
    "data = df[df.columns[:10]].values            #entire data set\n",
    "\n",
    "skf2 = StratifiedKFold(n_splits=13, random_state=331, shuffle=True) #used to reduce the size...\n",
    "for _ , index in skf2.split(data, y):\n",
    "    data = data[index]\n",
    "    y = y[index]\n",
    "    break;\n",
    "    \n",
    "tmp_cont = 0.1                               #first bet of 1-class prior\n",
    "k = 5                                        #number of new labels at each iteration (ntimes)\n",
    "ntimes = int(min(150, 0.5*len(data)) // k)   #number of querying iterations\n",
    "case = 2                                     #case 0 = perfect oracle, case 2 = imperfect oracle\n",
    "name_ds = 'PageBlocks'                       #if you want to give a name to the final result...\n",
    "n_splits = 5                                 #splits in crossvalidation (stratified)\n",
    "n_iter = 5                                   #number of runs of the whole method\n",
    "\n",
    "#This function runs the experiments. Pay attention that it saves 2 files: F1 results and prior results.\n",
    "df1 = get_f1scores_wdiff_priors(data, y, real_cont, tmp_cont, k, ntimes, name_ds, case, n_splits, n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
